{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (11.0.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (6.1.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\r2com\\anaconda33\\envs\\opencv-python3.10\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\n",
      "   ---------------------------------------- 0.0/899.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 899.0/899.0 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/44.8 MB 5.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.8/44.8 MB 4.2 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 2.6/44.8 MB 4.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 3.4/44.8 MB 3.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 4.5/44.8 MB 4.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/44.8 MB 4.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 6.6/44.8 MB 4.3 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 7.3/44.8 MB 4.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.9/44.8 MB 4.1 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 9.2/44.8 MB 4.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 10.0/44.8 MB 4.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 11.3/44.8 MB 4.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 12.3/44.8 MB 4.4 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 13.1/44.8 MB 4.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 14.2/44.8 MB 4.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 14.9/44.8 MB 4.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 16.3/44.8 MB 4.4 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 16.8/44.8 MB 4.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 18.1/44.8 MB 4.4 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 19.1/44.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 20.4/44.8 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 21.8/44.8 MB 4.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 23.1/44.8 MB 4.6 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 24.1/44.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 25.2/44.8 MB 4.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 26.5/44.8 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 28.0/44.8 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 28.8/44.8 MB 4.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 29.9/44.8 MB 4.8 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 30.7/44.8 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.7/44.8 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 33.0/44.8 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 33.8/44.8 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 34.9/44.8 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 36.2/44.8 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.7/44.8 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.7/44.8 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 38.8/44.8 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.2/44.8 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.0/44.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: py-cpuinfo, urllib3, tqdm, scipy, pyyaml, idna, charset-normalizer, certifi, requests, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 idna-3.10 py-cpuinfo-9.0.0 pyyaml-6.0.2 requests-2.32.3 scipy-1.14.1 seaborn-0.13.2 tqdm-4.67.1 ultralytics-8.3.50 ultralytics-thop-2.0.13 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision import models, transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', \n",
    "    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', \n",
    "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', \n",
    "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', \n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', \n",
    "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', \n",
    "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', \n",
    "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', \n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', \n",
    "    'toothbrush'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "cap = cv2.VideoCapture(\"./fig/fig/video/vtest.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"video no\")\n",
    "    sys.exit()\n",
    "model = YOLO(\"yolov10m.pt\") # 원하는 모델\n",
    "\n",
    "thershold = 0.6\n",
    "tm = cv2.TickMeter()\n",
    "Class_names=model.names\n",
    "\n",
    "while True:\n",
    "    tm.reset()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    fps_list = []\n",
    "    tm.start()\n",
    "    detection = model(frame, verbose = False)[0] # 실제 모델이 learning될때의 시간 \n",
    "    tm.stop()\n",
    "    total = tm.getTimeMilli()\n",
    "    \n",
    "    fps = f\"fps={1000/total:.3f}\"\n",
    "    fps_list.append(1000/total)\n",
    "\n",
    "    for data in detection.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "\n",
    "    if confidence > thershold:\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        label = int(data[5])\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        text = f\"{Class_names[label]}: {confidence*100:.2f}%\"\n",
    "        cv2.putText(frame, text, (xmin, ymin - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.putText(frame, fps, (20, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(30)==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean fps =  13.049310735406955\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"mean fps = \", np.mean(fps_list))\n",
    "plt.boxplot(fps_list, showfliers=False)\n",
    "plt.ylabel('FPS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.59M/5.59M [00:01<00:00, 4.67MB/s]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./fig/fig/video/vtest.avi\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"video open failed\")\n",
    "    sys.exit()\n",
    "\n",
    "model = YOLO(\"yolov10m.pt\")\n",
    "model =YOLO(\"yolov10n.pt\")\n",
    "\n",
    "threshold= 0.6\n",
    "tm=cv2.TickMeter()\n",
    "Class_names=model.names\n",
    "while True:\n",
    "    tm.reset()\n",
    "    ret,frame =cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    fps_list = []\n",
    "    tm.start()\n",
    "    detection = model(frame, verbose = False)[0] # 실제 모델이 learning될때의 시간 \n",
    "    tm.stop()\n",
    "    total = tm.getTimeMilli()\n",
    "    fps = f\"fps={1000/total:.3f}\"\n",
    "    fps_list.append(1000/total)\n",
    "\n",
    "    for data in detection.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "\n",
    "        if confidence > threshold:\n",
    "            xmin,ymin,xmax,ymax = int(data[0]),int(data[1]),int(data[2]),int(data[3]) \n",
    "            label=int(data[5])\n",
    "\n",
    "            cv2.rectangle(frame,(xmin ,ymin),(xmax ,ymax), (0,0,255),2)\n",
    "            label = f\"{Class_names[label]}:{confidence*100:.2f}%\"\n",
    "            cv2.putText(frame,label,(xmin,ymin-2),cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        1,(0,0,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame,fps,(20,20),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"fream\",frame)\n",
    "\n",
    "    if cv2.waitKey(30) ==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog_576x768.jpg', 'kite.jpg', 'person.jpg', 'sheep.jpg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## yolov3\n",
    "\n",
    "import os\n",
    "\n",
    "img_list = os.listdir(\"./fig/fig/object_detection\")\n",
    "print(img_list)\n",
    "\n",
    "img_paths = []\n",
    "for i in img_list:\n",
    "    img_path = \"./fig/fig/object_detection/\" + i # 폴더에 있는 것들 다 불러옴\n",
    "    img_paths.append(img_path)\n",
    "\n",
    "model = \"yolov3.weights\"\n",
    "config = \"yolov3.cfg\"\n",
    "class_labels = classNames\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"net empty\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "##출력 layer\n",
    "net.getUnconnectedOutLayers() # out layer\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.4 # IoU가 0.4이상 버린다 -> 같은 객체를 찾았을 확률이 큼\n",
    "for i in img_paths:\n",
    "    img = cv2.imread(i)\n",
    "\n",
    "    if img is None:\n",
    "        print(\"image failed\")\n",
    "        sys.exit()\n",
    "\n",
    "    # prequency\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (320, 320), swapRB=True) #swapRB R와 B채널을 바꿔서 넣어라.\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers) # 3군데에서 output을 뽑아라\n",
    "    # 그냥 forward만 하면 맨 앞에서만 출력돼서 한 파일 마다 모두 다 뽑기 위해선 output_layers\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # 이미지 마다 모든 과정을 다 해줘야됨됨\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            score = detection[5:]\n",
    "            class_id = np.argmax(score) # argmax(): 가장 높은 값이 있는 좌푯값\n",
    "            confidence = score[class_id] # 가장 높은 값이 있는 score 값\n",
    "            if confidence > confThreshold:\n",
    "                cx = int(detection[0]*w) # bbox의 center 값값\n",
    "                cy = int(detection[1]*h)\n",
    "                bw = int(detection[2]*w)\n",
    "                bh = int(detection[3]*h)\n",
    "\n",
    "                sx = int(cx-bw/2)\n",
    "                sy = int(cy-bh/2)\n",
    "                \n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "\n",
    "    for i in indices:\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = f\"{class_labels[class_ids[i]]}:{confidences[i]*100:.2f}%\"\n",
    "        cv2.rectangle(img, (sx, sy, bw, bh), (0, 0, 255), 1)\n",
    "        cv2.putText(img, label, (sx, sy-2), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]\n",
    "\n",
    "class_ids = []\n",
    "confidence = []\n",
    "boxes = []\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        score = detection[5:]\n",
    "        class_id = np.argmax(score) # argmax(): 가장 높은 값이 있는 좌푯값\n",
    "        confidence = score[class_id] # 가장 높은 값이 있는 score 값\n",
    "        if confidence > confThreshold:\n",
    "            cx = int(detection[0]*w) # bbox의 center 값값\n",
    "            cy = int(detection[1]*h)\n",
    "            cw = int(detection[2]*w)\n",
    "            ch = int(detection[3]*h)\n",
    "\n",
    "            sx = int(cx-bw/2)\n",
    "            sy = int(cy-bh/2)\n",
    "            \n",
    "            boxes.append([sx, sy, bw, bh])\n",
    "            confidence.append(confidence)\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
